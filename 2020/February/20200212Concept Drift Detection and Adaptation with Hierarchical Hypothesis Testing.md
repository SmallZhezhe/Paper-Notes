来自佛罗里达大学、罗伯特博世研究技术中心和华中师范大学的这篇文章，发展了之前贝尔实验室的那篇提出HHT的文章的做法，给出了一个比较完善的分析。

# 算法

作者同样是使用了这么一个架构，也就是先预警然后再验证的架构：

![image-20200210174505043](/home/liyunzhe/Pictures/typora_pic/image-20200210174505043.png)

与之不同的是，这篇文章的两层检验都不一样。

## 第一层

在这一层，作者使用了他们之前提出的一个叫做LFR的方法，这个方法对于各种类型的drift都很敏感，因为它同时对四个指标进行监测，对特征的监测比较全面，而别的方法都只抓住了部分特征：
$$
C=\left(\begin{matrix}
P_{tpr} & P_{tnr}\\
P_{ppv} & P_{npv}
\end{matrix}\right)\\
P_{tpr}是true\ positive\ rate，P_{tnr}是ture\ negative\ rate，\\P_{ppv}是positive\ predictive\ value，P_{npv}是negative\ predictive\ value
$$
在正常情况下，混淆矩阵C应该是不变的。如果C发生了改变，那么则可以认为是异常。

在实现的过程中，作者对分类器现在和过去的表现的线性组合R进行评价，H. Wang等人在2015年发表在IJCNN的一篇文章证明了R服从伯努利分布。基于这个事实，作者通过蒙特卡罗模拟得到了一个上界，一旦超过这个上界，就认为检测到了drift。

## 第二层

作者使用了一个排列的方法，来判断是否真的发生了改变，具体为：

先通过可能的drift的点之前的W个数据训练出一个分类器f，然后用f在这个点后面的W个数据样本上进行验证，得到一个损失Eord，接着，随机划分这些数据集P次，每次得到一个新的损失Ei。

如果是真的发生了异常，那么Eord应该比较大，也就是说满足：
$$
\frac{1+\sum_{i=1}^{P}{[\hat{E}_{ord}\le\hat{E}_i}]}{1+P}\le \eta
$$
否则就是假的。

## 迁移模型

作者还提出，只是用新数据去训练，严重恶化了模型的性能，并提出，可以用A-SVM的方法去进行迁移。

A-SVM由J. Yang与2007年提出，核心是通过训练，使得两个分类器f的区别尽可能的小：
$$
\min_w\frac{1}{2}{\|w-w^a\|}^2+C\sum_{i=1}^{N}\xi_i\\
s.t.\ \xi_i\ge0,\ y_iw^T\phi(X_i)\ge1-\xi_i,\ \forall(X_i,y_i)\in D
$$
在此便不再赘述。

# 性能

作者对HHT框架整体性能和具体算法的性能分别进行了分析。

## 框架理论分析

作者分析了这个架构对第一类错误和第二类错误的影响。

- 第一类错误又称Ⅰ型错误、拒真错误，是指拒绝了实际上成立的、正确的假设，为“弃真”的错误
- 第二类错误是指在进行[假设检验](https://baike.baidu.com/item/假设检验)时，原[假设](https://baike.baidu.com/item/假设)不正确，然而接受（未能拒绝）原假设的[错误](https://baike.baidu.com/item/错误)

### 第一类错误

这篇文章计算出了HHT的第一类错误：
$$
\alpha=\alpha_1\alpha_2\\
\alpha_1为第一层的第一类错误，\alpha_2是第二层的第一类错误
$$
这个结论说明，对于第一类错误而言，第一层的性能和第二层的性能是相互独立的。

同时，由于α一定是小于0的，因此有:
$$
\alpha\le\max(\alpha_1,\alpha_2)
$$
这意味着，即使在最坏的情况下，HHT架构也不会增加第一类错误。

### 第二类错误

同样作者计算出了HHT的第二类错误：
$$
\beta=\beta_1+(1-\beta_1)\beta_2
$$
这意味着：
$$
\beta_1\le \beta\le\beta_1+\max(1-\beta_1,\beta_2)
$$
这意味着HHT的框架会提高第二类错误的概率，即会提高误报率。

但是作者指出这并不是什么大问题，因为现在的算法的检测性能都很好，也就是说β都很小，这么一点的损失是可以接受的。

### 与ensemble of detectors的比较

作者将HHT的架构与另一个常用的架构ensemble of detectors进行了比较。在这个架构中，会使用很多的探测器，任意一个探测器有报错，则说明有错。

因此，这个架构的性能为：
$$
\alpha = 1-(1-\alpha_1)(1-\alpha_2)\cdots(1-\alpha_K)\\
\beta = \beta_1\beta_2\cdots\beta_K
$$
由上式，可以看出这样的一个架构可以显著降低第二类错误，但是会提高第一类错误的概率。考虑到现今第二类错误的可能性都很小，这个架构并没有太大的意义。

## 文中算法的性能

作者对两层的α和β分别进行了计算:

### 第一层

第一层的α就是算法中的显著性水平参数。

作者无法从理论上得到第一层的β，因此做了个实验，经验性的将β算了出来，图中的p是最开始的concept，q是变化之后的concept：

![image-20200212155800376](/home/liyunzhe/Pictures/typora_pic/image-20200212155800376.png)

得到了一个感觉没什么用的结论：差异越大，检测不出来的概率越小。

### 第二层

第二层的α同样是算法中给出的显著性水平。

但是作者依旧没能算出β。

引用了M. Harel在2014年证明的一个结论之后，作者指出，犯第二类错误的概率可以由下面的式子得到：
$$
P[|\hat{E}_{ord}-\hat{E}_{perm}|\le\Theta]\le\eta\\
\Theta=6W\gamma_W+\sqrt{4\log(\frac{4}{\eta})/W}+\Delta+\varepsilon\\
\gamma_n=O(\frac{1}{n})
$$
但是并没有给出更多的证明。

# 分析

文章给出了一个比较完善的HHT的性能分析，但是在第二层，本文依旧是使用有监督的方式去检测。HHT的架构的核心是先尽可能的将可能错误的点找出来然后再一个个的去验证，但是，如果不能使用label的话，或许很难找到一个无监督的算法，能对另一个无监督的算法找到的可能发生了drift的点进行验证。