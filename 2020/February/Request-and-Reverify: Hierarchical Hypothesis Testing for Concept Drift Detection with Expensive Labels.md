这篇贝尔实验室发的文章，通过无监督和有监督相结合的方式，尝试使用较少的标签，实现concept drift。

这也文章标题所说的分层的意思。大体架构如下：

![image-20200210174505043](/home/liyunzhe/Pictures/typora_pic/image-20200210174505043.png)

第一层采用无监督学习，直接判断。这将带来比较高的错误报警，也就是本不应该报错的被报出来了。而第二层则对第一层的报警，采用监督学习的方法来进行更准确的confirm，如果确实发生了concept drift，那么就更新模型，如果不是，则回到第一层继续下一个输入。

作者基于这个思路，提出了两个独立的算法，这两个算法都能解决这一问题，并且在不同的数据集上表现各有好坏。作者并没有对这两个算法进行比较，只是对这两个算法分别进行了测试。

# HHT-CU

这个算法对分类误差(classification uncertainty)进行检验。

分类误差是这么定义的：
$$
u_t=\|y_t-P(y_t|X_t)\|_2\\P(y_t|X_t)是由分类器得到的预测成y_t的概率，而y_t是预测的类别。
$$

这里面提到了一个概念1-of-K coding schem，这是一种编码方式，是指将K类编码为1到K。作者在这里规定了编码方式，因为编码方式和u的值直接相关。

在无监督的第一层，这个算法使用Hoeffding's inequality[1963]去监测分类误差u的移动平均(moving average)。

检验规则如下：
$$
X:前cut个样本的分类误差\\
Z:目前为止检测的所有样本的分类误差\\
假设H_0:E(\overline{X})>E(\overline{Z})\\
在显著水平\alpha下，使得\overline{Z}-\overline{X}\ge \epsilon_\alpha\\
这里有\epsilon_\alpha = \sqrt{\frac{K-1}{K}}\times \sqrt{\frac{m}{2n(n+m)}ln\frac{1}{\alpha}},K为分类的种类数目
$$
无监督检验的过程中作者做了这么一个假设：
$$
\overline{X}_i+\epsilon_{\overline{X}_i}<\overline{Z}_i+\epsilon_{\overline{Z}_i}
$$
因为在没有发生concept drift的时候，X应该是比较小的，因此整个式子也相应的应该比较小。而Z有可能发生了concept，所以会比较大。这里引用了两篇文章，因此没写很详细。

一旦检验被拒绝，也就是说发生了较大的变化，便加入到potential集里面，此时进入监督检验。

监督检验过程很简单，就是在前后两处各取N个点重新训练，然后都在这个点出进行验证，如果差异较大，便认为确实发生了concept drift。接着就更新参数继续检测。否则就放弃这个点继续检测。

# HHT-AG

这个方法同样是分为有监督和无监督的两个部分。

这个方法使用了一个被广泛使用但是并没有很严格的理论基础的一个方法：
$$
在进行多变量的change检测的时候，将P_{t}(X)分解为\prod_{k=1}^{d}P_t(x^k)
$$
这个方法维护了两个活动窗口W1和W2，然后对X里面的每一个属性x进行KS检验，无监督的检验分布是否变化：
$$
\sup_x |F_A(x)-F_B(x)|>s(\alpha)\sqrt{\frac{m+n}{mn}}\\
这里的F_C(x)=\frac{1}{|C|}\sum1_{\{c\in C,c\le x\}},s(\alpha)为一个经验值，m和n分别为集合A和B的基数
$$
只要任何一个属性x发生了变化就认为可能发生了concept drift，进入有监督的检验。

有监督的检验是基于朴素贝叶斯假设的，是通过二维KS检验，增加的一个维度是label。加上label之后，如果有任意一个属性x和y一起的显著性检验还拒绝，那么说明检测到了concept drift，进行更新。

# 分析

虽然作者没有进行分析，但是实验结果显示大多数情况下，HHT-CU效果是比HHT-AG要好。一般情况下两者都能达到比较好的效果。这样的一个首先进行无监督检验，然后再进行有监督检验的方法能够显著降低需要的真实标签的数量，也能达到和纯粹的有监督检验差不多甚至某些数据集下更好的效果。

作者提出了两种算法，这两种方法的效果已经足够好了。同时，在这个思路指导下，或许还可以找出更好的方法。

